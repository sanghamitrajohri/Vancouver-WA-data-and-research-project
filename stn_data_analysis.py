# -*- coding: utf-8 -*-
"""STN_Data_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rheHPxBJ7mNu5UIl-Gy2sTf1ZZcbP3Is
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

# Load the data from the CSV file
file_path = '/content/load_data.csv'  # Replace with the correct file path
load_data = pd.read_csv(file_path)

# Display the first few rows of the dataframe
load_data.head()

# Convert the 'Time' column to datetime format for easier plotting
load_data['Time'] = pd.to_datetime(load_data['Time'])

# Plot STN01 electricity consumption over time
plt.figure(figsize=(12, 6))
plt.plot(load_data['Time'], load_data['STN48'], label='STN01 Electricity Consumption', color='blue')
plt.xlabel('Time')
plt.ylabel('Electricity Consumption (kW)')
plt.title('Electricity Consumption of STN01 Over Time')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Calculate the total electricity consumption for each station
total_consumption = load_data.iloc[:, 1:].sum()

# Create a dataframe for better visualization
total_consumption_df = total_consumption.reset_index()
total_consumption_df.columns = ['Station', 'Total Consumption (mW)']

# Format the 'Total Consumption' column to avoid scientific notation
total_consumption_df['Total Consumption (mW)'] = total_consumption_df['Total Consumption (mW)'].apply(lambda x: f"{x:,.2f}")
total_consumption_df
sum = total_consumption_df['Total Consumption (mW)'].sum()
total_consumption_df.to_csv('total_consumption.csv', index=False)

# Remove STN38 from the dataframe
filtered_consumption_df = total_consumption_df[total_consumption_df['Station'] != 'STN38']

# Find the station with the minimum total consumption again
min_consumption_filtered_stn = filtered_consumption_df.loc[filtered_consumption_df['Total Consumption (mW)'].idxmin()]
min_consumption_filtered_stn

# Find the station with the maximum total consumption again
max_consumption_stn = total_consumption_df.loc[total_consumption_df['Total Consumption (mW)'].idxmax()]
max_consumption_stn

"""Addressing the missing values"""

# Load your data
load_data = pd.read_csv('load_data.csv')

# Handling Missing Values
# Fill missing values only in numeric columns with the mean
numeric_columns = load_data.select_dtypes(include=['number']).columns
load_data[numeric_columns] = load_data[numeric_columns].fillna(load_data[numeric_columns].mean())

# Save the cleaned dataset to a new CSV file
load_data.to_csv('cleaned_load_data.csv', index=False)
print("Cleaned dataset saved as 'cleaned_load_data.csv'.")

# Calculate the total electricity consumption for each station
total_consumption = load_data.iloc[:, 1:].sum()

# Create a dataframe for better visualization
total_consumption_df = total_consumption.reset_index()
total_consumption_df.columns = ['Station', 'Total Consumption (mW)']

# Format the 'Total Consumption' column to avoid scientific notation
total_consumption_df['Total Consumption (mW)'] = total_consumption_df['Total Consumption (mW)'].apply(lambda x: f"{x:,.2f}")

# Display the total consumption
print(total_consumption_df)

# Save the total consumption to a CSV file
total_consumption_df.to_csv('total_consumption.csv', index=False)
print("Total consumption saved as 'total_consumption.csv'.")

# Remove STN38 from the dataframe
filtered_consumption_df = total_consumption_df[total_consumption_df['Station'] != 'STN38']

# Find the station with the minimum total consumption again
min_consumption_filtered_stn = filtered_consumption_df.loc[filtered_consumption_df['Total Consumption (mW)'].idxmin()]
print("Station with minimum consumption (excluding STN38):")
print(min_consumption_filtered_stn)

# Find the station with the maximum total consumption again
max_consumption_stn = total_consumption_df.loc[total_consumption_df['Total Consumption (mW)'].idxmax()]
print("Station with maximum consumption:")
print(max_consumption_stn)

data = pd.read_csv('load_data.csv')

# Ensure the 'Time' column is in datetime format
if 'Time' in load_data.columns:
    load_data['Time'] = pd.to_datetime(load_data['Time'])

# Handle missing values for all stations except STN38
numeric_columns = load_data.select_dtypes(include=['number']).columns
columns_to_impute = numeric_columns.drop('STN38', errors='ignore')  # Exclude STN38
load_data[columns_to_impute] = load_data[columns_to_impute].fillna(load_data[columns_to_impute].mean())

# Remove STN38 completely from the dataset
if 'STN38' in load_data.columns:
    load_data = load_data.drop(columns=['STN38'])

# Save the cleaned dataset to a new CSV file
load_data.to_csv('cleaned_load_data_without_stn38.csv', index=False)
print("Cleaned dataset saved as 'cleaned_load_data_without_stn38.csv'.")

# Outlier Detection using Isolation Forest on the cleaned data
numeric_data_cleaned = load_data.select_dtypes(include=['number'])  # Use only numeric columns

# Using Isolation Forest for outlier detection
model_cleaned = IsolationForest(contamination=0.01, random_state=42)  # 1% of data assumed as outliers
outlier_labels_cleaned = model_cleaned.fit_predict(numeric_data_cleaned)

# Add outlier labels to the cleaned dataset
load_data['Outlier'] = outlier_labels_cleaned

# Separate outliers and inliers for visualization
outliers_cleaned = load_data[load_data['Outlier'] == -1]
inliers_cleaned = load_data[load_data['Outlier'] == 1]

# Visualize outliers for a selected station (e.g., STN01)
plt.figure(figsize=(12, 6))
plt.plot(load_data['Time'], load_data['STN01'], color='blue', label='Inliers (STN01)', alpha=0.7, linewidth=0.7)
plt.scatter(outliers_cleaned['Time'], outliers_cleaned['STN01'], color='red', label='Outliers (STN01)', s=20)

# Format the plot
plt.title('Outlier Detection in STN01 Consumption (Cleaned Data)')
plt.xlabel('Time')
plt.ylabel('Consumption (mW)')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Count and display the number of outliers detected
outlier_count_cleaned = len(outliers_cleaned)
outlier_count_cleaned

# Group outliers by month and year for visualization
outliers_cleaned['Month'] = outliers_cleaned['Time'].dt.month
outliers_cleaned['Year'] = outliers_cleaned['Time'].dt.year
outliers_grouped = outliers_cleaned.groupby(['Year', 'Month']).size().reset_index(name='Outlier Count')

# Pivot the data for better visualization in a heatmap-style bar plot
outliers_pivot = outliers_grouped.pivot(index='Month', columns='Year', values='Outlier Count')

# Plot the heatmap-style bar plot
plt.figure(figsize=(10, 6))
outliers_pivot.plot(kind='bar', stacked=True, colormap='viridis', figsize=(12, 6))

plt.title('Monthly Distribution of Outliers by Year')
plt.xlabel('Month')
plt.ylabel('Outlier Count')
plt.legend(title='Year')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()